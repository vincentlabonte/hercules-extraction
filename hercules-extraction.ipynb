{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERCULES-EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HERCULES-EXTRACTION is an extraction tool which goal is to extract named entities from a text. To do so, we use already functional tools and APIs that are built for English texts. To be able to use these tools and APIs, we first need to [translate](#Translation) the text to English. After the text has been translated, we [extract entities](#Entity-Extraction) from the translated text using differents tools and APIs. We also use a [coreference resolution](#Coreference-Resolution) approach to filter the different extracted entities. Then, we [translate back](#Translation-Back) the entities and we [export](#Export) the triples to a rdf format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import subprocess \n",
    "import sys\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_path = Path('setup')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prerequisites**:\n",
    "- Java 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install -r requirements.txt -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up all the components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AzureTranslator**\n",
    "\n",
    "Set the `AZURE_TOKEN` environment variable to an Azure Text API key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AZURE_TOKEN'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GoogleCloudTranslator** and **GoogleEntityExtractor**\n",
    "\n",
    "Set the `GOOGLE_APPLICATION_CREDENTIALS` environment variable to a Google service account JSON keyfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MyMemoryTranslator**\n",
    "\n",
    "Set the `MYMEMORY_TOKEN` environment variable to a MyMemory API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MYMEMORY_TOKEN'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DandelionEntityExtractor**\n",
    "\n",
    "Set the `DANDELION_TOKEN` environment variable to a Dandelion API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['DANDELION_TOKEN'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**StanfordCoreferenceResolver**\n",
    "\n",
    "Download the Stanford CoreNLP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corenlp_zip_path = setup_path / 'stanford-corenlp-full-2018-10-05.zip'\n",
    "corenlp_dir_path = setup_path / 'stanford-corenlp-full-2018-10-05'\n",
    "corenlp_url = 'http://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip'\n",
    "\n",
    "setup_path.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "if not corenlp_zip_path.is_file():\n",
    "    response = requests.get(corenlp_url)\n",
    "    with corenlp_zip_path.open('wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "if not corenlp_dir_path.is_dir():\n",
    "    with zipfile.ZipFile(corenlp_zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(setup_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the Stanford CoreNLP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corenlp_server = subprocess.Popen(['java', '-Xmx5G', '-cp', str(corenlp_dir_path.resolve() / '*'), 'edu.stanford.nlp.pipeline.StanfordCoreNLPServer', '-port 9000', '-timeout 60000', '-threads 5', '-maxCharLength 100000', '-quiet True', '-preload tokenize,ssplit,pos,lemma,ner,parse,coref'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the `CORENLP_HOME` environment variable to the path of the Stanford CoreNLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CORENLP_HOME'] = str(corenlp_dir_path.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import translation\n",
    "import extraction\n",
    "import coreference\n",
    "import export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the text from a file. For this example we picked a text about Notre-Dame Basilica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_language = 'fr'\n",
    "extraction_language = 'en'\n",
    "\n",
    "text_path = Path('sample', 'default', 'text.txt')\n",
    "text = text_path.read_text(encoding='utf-8')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate the text to English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AzureTranslator**\n",
    "\n",
    "This translator uses the Azure Text API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_translator = translation.AzureTranslator()\n",
    "azure_translated_text = azure_translator.translate(text, text_language, extraction_language)\n",
    "print(azure_translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GoogleCloudTranslator**\n",
    "\n",
    "This translator uses the Google Translation Cloud API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_translator = translation.GoogleCloudTranslator()\n",
    "google_translated_text = google_translator.translate(text, text_language, extraction_language)\n",
    "print(google_translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GoogletransTranslator**\n",
    "\n",
    "This translator uses the Google Translation website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "googletrans_translator = translation.GoogletransTranslator()\n",
    "googletrans_translated_text = googletrans_translator.translate(text, text_language, extraction_language)\n",
    "\n",
    "print(googletrans_translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MyMemoryTranslator**\n",
    "\n",
    "This translator uses the MyMemory API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_memory_translator = translation.MyMemoryTranslator()\n",
    "my_memory_translated_text = my_memory_translator.translate(text, text_language, extraction_language)\n",
    "print(my_memory_translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the MyMemory translated text for the following tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = my_memory_translator\n",
    "translated_text = my_memory_translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the entities from the translated text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DandelionEntityExtractor**\n",
    "\n",
    "This entity extractor uses the Dandelion API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dandelion_entity_extractor = extraction.DandelionEntityExtractor()\n",
    "dandelion_entities = dandelion_entity_extractor.extract_entities(translated_text)\n",
    "for entity in dandelion_entities:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GoogleEntityExtractor**\n",
    "\n",
    "This entity extractor uses the Google Natural Language API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_entity_extractor = extraction.GoogleEntityExtractor()\n",
    "google_entities = google_entity_extractor.extract_entities(translated_text)\n",
    "for entity in google_entities:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the Dandelion entities for the following tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_entities = dandelion_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coreference Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_coreference = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the previously extracted entities using some coreference resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_entity_from_mention(mention):\n",
    "    if len(mention) <= 0:\n",
    "        return None\n",
    "    for entity in mention:\n",
    "        if entity.entity_type != extraction.EntityType.THING:\n",
    "            return entity\n",
    "    return mention[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**StanfordCoreferenceResolver**\n",
    "\n",
    "This coreference resolver uses a local intance of the Stanford CoreNLP server. If there is a `Read timed out` error, you can skip this step by changing `skip_coreference` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_coreference:\n",
    "    stanford_coreference_resolver = coreference.StanfordCoreferenceResolver(start_server=False, endpoint='http://localhost:9000')\n",
    "    stanford_mentions = stanford_coreference_resolver.resolve_coreferences(translated_text, extracted_entities)\n",
    "\n",
    "    stanford_filtered_entities = []\n",
    "    for mention in stanford_mentions:\n",
    "        entity = get_relevant_entity_from_mention(mention)\n",
    "        if entity is not None:\n",
    "            stanford_filtered_entities.append(entity)\n",
    "\n",
    "    for entity in stanford_filtered_entities:\n",
    "        print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the Stanford filtered entities for the following tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip_coreference:\n",
    "    filtered_entities = extracted_entities\n",
    "else:\n",
    "    filtered_entities = stanford_filtered_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation Back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate back the filtered entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_back_entities = []\n",
    "for entity in filtered_entities:\n",
    "    entity_name = translator.translate(entity.name, extraction_language, text_language)\n",
    "    translated_back_entity = extraction.Entity(entity_name, entity.entity_type, None, None)\n",
    "    translated_back_entities.append(translated_back_entity)\n",
    "    print(translated_back_entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the translated back entities to an rdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = Path('notebook-export')\n",
    "export_path.mkdir(parents=True, exist_ok=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIDOCCRMExporter**\n",
    "\n",
    "This exporter is specifically crafted to work with the [CIDOC CRM ontology](http://www.cidoc-crm.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_language = 'turtle'\n",
    "entity_namespace = 'http://culture.gouv.qc.ca/entity/'\n",
    "ontology_namespace = 'http://www.cidoc-crm.org/cidoc-crm/'\n",
    "cidoccrm_export_path = export_path / 'cidoccrm.ttl'\n",
    "\n",
    "cidoccrm_exporter = export.CIDOCCRMExporter()\n",
    "cidoccrm_export = cidoccrm_exporter.export(translated_back_entities, entity_namespace, ontology_namespace, export_language)\n",
    "\n",
    "cidoccrm_export_path.write_text(cidoccrm_export, encoding='utf-8')\n",
    "print(cidoccrm_export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "Kill the CoreNLP server spawned by this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corenlp_server.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
