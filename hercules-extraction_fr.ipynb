{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERCULES-EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HERCULES-EXTRACTION est un outil d'extraction qui a pour but l'extraction d'entitées nommées dans un texte. Pour ce faire, nous utilisons des outils et APIs déjà fonctionels pour les textes en anglais. Pour être capable d'utiliser ces outils et APIs, nous devons tout d'abord [traduire le texte](#Traduction-du-texte) en anglais. Après avoir avoir traduit le texte, nous utilisons les différents outils et APIs pour [extraire les entitées nommées](#Extraction-d'entitées). Nous utilisons aussi une approche de [résolution de la coréférence](#Résolution-de-la-coréférence) afin de filtrer les entitéess précédement extraites. Enfin, nous [traduisons les entitées](#Traduction-des-entitées) extraites en français et nous [exportons](#Exportation) les triplets sous format rdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import subprocess\n",
    "import sys\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurons le notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_path = Path('setup')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prérequis**:\n",
    "- Java 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installons les requis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install -r requirements.txt -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuront les composantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AzureTranslator**\n",
    "\n",
    "Définissons la variable d'environnement `AZURE_TOKEN` à notre clé d'Azure Text API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AZURE_TOKEN'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GoogleCloudTranslator** and **GoogleEntityExtractor**\n",
    "\n",
    "Définissons la variable d'environnement `GOOGLE_APPLICATION_CREDENTIALS` à notre « Google service account JSON keyfile »."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MyMemoryTranslator**\n",
    "\n",
    "Définissons la variable d'environnement `MYMEMORY_TOKEN` à notre clé de MyMemory API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MYMEMORY_TOKEN'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DandelionEntityExtractor**\n",
    "\n",
    "Définissons la variable d'environnement `DANDELION_TOKEN` à notre clé de Dandelion API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['DANDELION_TOKEN'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**StanfordCoreferenceResolver**\n",
    "\n",
    "Téléchargeons le serveur Stanford CoreNLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corenlp_zip_path = setup_path / 'stanford-corenlp-full-2018-10-05.zip'\n",
    "corenlp_dir_path = setup_path / 'stanford-corenlp-full-2018-10-05'\n",
    "corenlp_url = 'http://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip'\n",
    "\n",
    "setup_path.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "if not corenlp_zip_path.is_file():\n",
    "    response = requests.get(corenlp_url)\n",
    "    with corenlp_zip_path.open('wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "if not corenlp_dir_path.is_dir():\n",
    "    with zipfile.ZipFile(corenlp_zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(setup_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Démarrons le serveur Stanford CoreNLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corenlp_server = subprocess.Popen(['java', '-Xmx5G', '-cp', str(corenlp_dir_path.resolve() / '*'), 'edu.stanford.nlp.pipeline.StanfordCoreNLPServer', '-port 9000', '-timeout 60000', '-threads 5', '-maxCharLength 100000', '-quiet True', '-preload tokenize,ssplit,pos,lemma,ner,parse,coref'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons la variable d'environnement `CORENLP_HOME` au chemin du serveur Stanford CoreNLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CORENLP_HOME'] = str(corenlp_dir_path.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valeurs initiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import translation\n",
    "import extraction\n",
    "import coreference\n",
    "import export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allons chercher le texte à partir d'un fichier. Pour cet exemple, nous avons choisis un text à propos de la Basilique Notre-Dame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_language = 'fr'\n",
    "extraction_language = 'en'\n",
    "\n",
    "text_path = Path('sample', 'default', 'text.txt')\n",
    "text = text_path.read_text(encoding='utf-8')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traduction du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traduisons le texte en anglais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AzureTranslator**\n",
    "\n",
    "Ce traducteur utilise l'API d'Azure Text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_translator = translation.AzureTranslator()\n",
    "azure_translated_text = azure_translator.translate(text, text_language, extraction_language)\n",
    "print(azure_translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GoogleCloudTranslator**\n",
    "\n",
    "Ce traducteur utilise l'API de Google Translation Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_translator = translation.GoogleCloudTranslator()\n",
    "google_translated_text = google_translator.translate(text, text_language, extraction_language)\n",
    "print(google_translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GoogletransTranslator**\n",
    "\n",
    "Ce traducteur utilise le site web de Google Translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "googletrans_translator = translation.GoogletransTranslator()\n",
    "googletrans_translated_text = googletrans_translator.translate(text, text_language, extraction_language)\n",
    "\n",
    "print(googletrans_translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MyMemoryTranslator**\n",
    "\n",
    "Ce traducteur utilise l'API de MyMemory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_memory_translator = translation.MyMemoryTranslator()\n",
    "my_memory_translated_text = my_memory_translator.translate(text, text_language, extraction_language)\n",
    "print(my_memory_translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prenons le texte traduit par MyMemory pour les prochaines étapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = my_memory_translator\n",
    "translated_text = my_memory_translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction d'entitées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extractons les entitées à partir du texte traduit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DandelionEntityExtractor**\n",
    "\n",
    "Cet extracteur d'entitées utilise l'API de Dandelion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dandelion_entity_extractor = extraction.DandelionEntityExtractor()\n",
    "dandelion_entities = dandelion_entity_extractor.extract_entities(translated_text)\n",
    "for entity in dandelion_entities:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GoogleEntityExtractor**\n",
    "\n",
    "Cet extracteur d'entitées utilise l'API de Google Natural Language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_entity_extractor = extraction.GoogleEntityExtractor()\n",
    "google_entities = google_entity_extractor.extract_entities(translated_text)\n",
    "for entity in google_entities:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prenons les entitées extraites par Dandelion pour les prochaines étapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_entities = dandelion_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résolution de la coréférence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_coreference = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrons les entitées précédement extraites en utilisant de la résolution de coréférence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_entity_from_mention(mention):\n",
    "    if len(mention) <= 0:\n",
    "        return None\n",
    "    for entity in mention:\n",
    "        if entity.entity_type != extraction.EntityType.THING:\n",
    "            return entity\n",
    "    return mention[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**StanfordCoreferenceResolver**\n",
    "\n",
    "Ce résolveur de coréférence utilise une instance locale du serveur de Stanford CoreNLP. S'il y a une erreur `Read timed out`, vous pouvez passer cette étape en changeant `skip_coreference` à `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_coreference:\n",
    "    stanford_coreference_resolver = coreference.StanfordCoreferenceResolver(start_server=False, endpoint='http://localhost:9000')\n",
    "    stanford_mentions = stanford_coreference_resolver.resolve_coreferences(translated_text, extracted_entities)\n",
    "\n",
    "    stanford_filtered_entities = []\n",
    "    for mention in stanford_mentions:\n",
    "        entity = get_relevant_entity_from_mention(mention)\n",
    "        if entity is not None:\n",
    "            stanford_filtered_entities.append(entity)\n",
    "\n",
    "    for entity in stanford_filtered_entities:\n",
    "        print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prenons les entitées filtrées avec Stanford pour les prochaines étapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip_coreference:\n",
    "    filtered_entities = extracted_entities\n",
    "else:\n",
    "    filtered_entities = stanford_filtered_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traduction des entitées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traduisons les entitées filtrées en français."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_back_entities = []\n",
    "for entity in filtered_entities:\n",
    "    entity_name = translator.translate(entity.name, extraction_language, text_language)\n",
    "    translated_back_entity = extraction.Entity(entity_name, entity.entity_type, None, None)\n",
    "    translated_back_entities.append(translated_back_entity)\n",
    "    print(translated_back_entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportons les entitées traduites vers un fichier rdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = Path('notebook-export')\n",
    "export_path.mkdir(parents=True, exist_ok=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIDOCCRMExporter**\n",
    "\n",
    "Cet exporteur est conçu pour fonctionner avec l'ontologie de la [CIDOC CRM](http://www.cidoc-crm.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_language = 'turtle'\n",
    "entity_namespace = 'http://culture.gouv.qc.ca/entity/'\n",
    "ontology_namespace = 'http://www.cidoc-crm.org/cidoc-crm/'\n",
    "cidoccrm_export_path = export_path / 'cidoccrm.ttl'\n",
    "\n",
    "cidoccrm_exporter = export.CIDOCCRMExporter()\n",
    "cidoccrm_export = cidoccrm_exporter.export(translated_back_entities, entity_namespace, ontology_namespace, export_language)\n",
    "\n",
    "cidoccrm_export_path.write_text(cidoccrm_export, encoding='utf-8')\n",
    "print(cidoccrm_export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage du notebook\n",
    "\n",
    "Arrête le serveur CoreNLP créé par ce notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corenlp_server.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
